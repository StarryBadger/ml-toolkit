{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necessary Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join('..', '..', 'models', 'cnn')))\n",
    "from cnn import CNN\n",
    "from multilabel_cnn import MultiLabelCNN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a function load mnist data() that extracts images from the\n",
    "dataset folders and organizes them into separate lists for images and labels\n",
    "corresponding to the train, validation, and test splits. Ensure that the\n",
    "images are loaded from their respective folders without any overlap or\n",
    "mixing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist_data(base_path='../../data/external/double_mnist', use_label_count=False):\n",
    "    images = {\n",
    "        'train': [],\n",
    "        'val': [],\n",
    "        'test': []\n",
    "    }\n",
    "    labels = {\n",
    "        'train': [],\n",
    "        'val': [],\n",
    "        'test': []\n",
    "    }\n",
    "\n",
    "    splits = ['train', 'val', 'test']\n",
    "    for split in splits:\n",
    "        split_path = os.path.join(base_path, split)\n",
    "        for label in os.listdir(split_path):\n",
    "            label_path = os.path.join(split_path, label)\n",
    "            if os.path.isdir(label_path):\n",
    "                for img_name in os.listdir(label_path):\n",
    "                    img_path = os.path.join(label_path, img_name)\n",
    "                    img = Image.open(img_path).convert('L')\n",
    "                    img_array = np.array(img)\n",
    "                    images[split].append(img_array)\n",
    "\n",
    "                    if use_label_count:\n",
    "                        if label == \"0\":\n",
    "                            label_count = 0\n",
    "                        else:\n",
    "                            label_count = len(label)\n",
    "                        labels[split].append(label_count)\n",
    "                    else:\n",
    "                        labels[split].append(one_hot_encode_label(label))\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "images, labels = load_mnist_data(use_label_count=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a class called MultiMNISTDataset that will be used to create\n",
    "dataloaders for training and evaluation purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "class MultiMNISTDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        img = torch.tensor(img, dtype=torch.float32) / 255.0  \n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),         \n",
    "    transforms.Resize((28, 28)),     \n",
    "    transforms.ToTensor(),         \n",
    "])\n",
    "\n",
    "train_dataset = MultiMNISTDataset(images['train'], labels['train'], transform=transform)\n",
    "val_dataset = MultiMNISTDataset(images['val'], labels['val'], transform=transform)\n",
    "test_dataset = MultiMNISTDataset(images['test'], labels['test'], transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the CNN Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./figures/cnn_loss_plots/plot.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5: 100%|██████████| 394/394 [00:19<00:00, 20.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Training Loss: 0.1568, Validation Loss: 0.0153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/5: 100%|██████████| 394/394 [00:18<00:00, 20.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5], Training Loss: 0.0324, Validation Loss: 0.0098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/5: 100%|██████████| 394/394 [00:19<00:00, 20.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5], Training Loss: 0.0285, Validation Loss: 0.0080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/5: 100%|██████████| 394/394 [00:19<00:00, 20.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5], Training Loss: 0.0264, Validation Loss: 0.0156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/5: 100%|██████████| 394/394 [00:19<00:00, 20.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5], Training Loss: 0.0263, Validation Loss: 0.0052\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = CNN(task='regression', num_classes=4, num_conv_layers=3,dropout_rate=0.2, optimizer_choice='adam', device=device).to(device)\n",
    "model.fit(train_loader, val_loader, epochs=5, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   True Labels  Predictions Correctness\n",
      "0            3          3.0           ✓\n",
      "1            3          3.0           ✓\n",
      "2            3          3.0           ✓\n",
      "3            3          3.0           ✓\n",
      "4            3          3.0           ✓\n",
      "Results saved to predictions.csv\n",
      "Test Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def calculate_accuracy(model, test_loader, output_file='predictions.csv'):\n",
    "    model.eval()\n",
    "    predictions = model.predict(test_loader)\n",
    "    \n",
    "    true_labels = []\n",
    "    for _, labels in test_loader:\n",
    "        true_labels.append(labels)\n",
    "    true_labels = torch.cat(true_labels).cpu()\n",
    "    predictions = torch.round(predictions).cpu()\n",
    "    \n",
    "    # Create a DataFrame to display true labels, predictions, and correctness\n",
    "    results_df = pd.DataFrame({\n",
    "        'True Labels': true_labels.numpy(),\n",
    "        'Predictions': predictions.numpy(),\n",
    "        'Correctness': ['✓' if true == pred else 'x' for true, pred in zip(true_labels.numpy(), predictions.numpy())]\n",
    "    })\n",
    "    \n",
    "    print(results_df.head())\n",
    "    results_df.to_csv(output_file, index=False)\n",
    "    print(f\"Results saved to {output_file}\")\n",
    "    \n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "    return accuracy\n",
    "\n",
    "accuracy = calculate_accuracy(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./figures/cnn_loss_plots/classification_loss_combination_1_lr_0.001_dropout_0.3_layers_2_opt_adam.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/2: 100%|██████████| 394/394 [00:14<00:00, 27.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Training Loss: 0.2117, Validation Loss: 0.0053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/2: 100%|██████████| 394/394 [00:14<00:00, 26.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Training Loss: 0.0083, Validation Loss: 0.0032\n",
      "./figures/cnn_loss_plots/classification_loss_combination_2_lr_0.001_dropout_0.5_layers_3_opt_adam.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/2: 100%|██████████| 394/394 [00:16<00:00, 23.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Training Loss: 0.2935, Validation Loss: 0.0028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/2: 100%|██████████| 394/394 [00:12<00:00, 32.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Training Loss: 0.0105, Validation Loss: 0.0071\n",
      "./figures/cnn_loss_plots/classification_loss_combination_3_lr_0.0005_dropout_0.5_layers_2_opt_sgd.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/2: 100%|██████████| 394/394 [00:09<00:00, 41.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Training Loss: 1.1696, Validation Loss: 1.0771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/2: 100%|██████████| 394/394 [00:09<00:00, 41.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Training Loss: 1.1167, Validation Loss: 1.0460\n",
      "./figures/cnn_loss_plots/classification_loss_combination_4_lr_0.0005_dropout_0.3_layers_3_opt_sgd.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/2: 100%|██████████| 394/394 [00:11<00:00, 35.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Training Loss: 1.2357, Validation Loss: 1.0965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/2: 100%|██████████| 394/394 [00:11<00:00, 33.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Training Loss: 1.1357, Validation Loss: 1.0845\n",
      "./figures/cnn_loss_plots/classification_loss_combination_5_lr_0.0001_dropout_0.5_layers_4_opt_adam.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/2: 100%|██████████| 394/394 [00:13<00:00, 28.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Training Loss: 0.7668, Validation Loss: 0.0730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/2: 100%|██████████| 394/394 [00:13<00:00, 29.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Training Loss: 0.0397, Validation Loss: 0.0144\n",
      "./figures/cnn_loss_plots/regression_loss_combination_1_lr_0.001_dropout_0.3_layers_2_opt_adam.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/2: 100%|██████████| 394/394 [00:11<00:00, 34.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Training Loss: 0.1814, Validation Loss: 0.0304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/2: 100%|██████████| 394/394 [00:11<00:00, 34.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Training Loss: 0.0627, Validation Loss: 0.0196\n",
      "./figures/cnn_loss_plots/regression_loss_combination_2_lr_0.001_dropout_0.5_layers_3_opt_adam.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/2: 100%|██████████| 394/394 [00:13<00:00, 29.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Training Loss: 0.2237, Validation Loss: 0.0644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/2: 100%|██████████| 394/394 [00:12<00:00, 31.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Training Loss: 0.0965, Validation Loss: 0.1127\n",
      "./figures/cnn_loss_plots/regression_loss_combination_3_lr_0.0005_dropout_0.5_layers_2_opt_sgd.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/2: 100%|██████████| 394/394 [00:11<00:00, 34.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Training Loss: 0.6034, Validation Loss: 0.2043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/2: 100%|██████████| 394/394 [00:11<00:00, 35.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Training Loss: 0.2040, Validation Loss: 0.1193\n",
      "./figures/cnn_loss_plots/regression_loss_combination_4_lr_0.0005_dropout_0.3_layers_3_opt_sgd.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/2: 100%|██████████| 394/394 [00:12<00:00, 30.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Training Loss: 0.7498, Validation Loss: 0.2468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/2: 100%|██████████| 394/394 [00:12<00:00, 31.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Training Loss: 0.2516, Validation Loss: 0.1488\n",
      "./figures/cnn_loss_plots/regression_loss_combination_5_lr_0.0001_dropout_0.5_layers_4_opt_adam.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/2: 100%|██████████| 394/394 [00:12<00:00, 31.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Training Loss: 0.6441, Validation Loss: 0.1403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/2: 100%|██████████| 394/394 [00:12<00:00, 30.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Training Loss: 0.1625, Validation Loss: 0.0365\n",
      "Best Classification Model Combination: {'lr': 0.001, 'dropout_rate': 0.3, 'num_conv_layers': 2, 'optimizer_choice': 'adam'}\n",
      "Best Regression Model Combination: {'lr': 0.001, 'dropout_rate': 0.3, 'num_conv_layers': 2, 'optimizer_choice': 'adam'}\n",
      "Best parameters saved to ./figures/cnn_loss_plots/best_model_params.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "hyperparam_combinations = [\n",
    "    {'lr': 0.001, 'dropout_rate': 0.3, 'num_conv_layers': 2, 'optimizer_choice': 'adam'},\n",
    "    {'lr': 0.001, 'dropout_rate': 0.5, 'num_conv_layers': 3, 'optimizer_choice': 'adam'},\n",
    "    {'lr': 0.0005, 'dropout_rate': 0.5, 'num_conv_layers': 2, 'optimizer_choice': 'sgd'},\n",
    "    {'lr': 0.0005, 'dropout_rate': 0.3, 'num_conv_layers': 3, 'optimizer_choice': 'sgd'},\n",
    "    {'lr': 0.0001, 'dropout_rate': 0.5, 'num_conv_layers': 4, 'optimizer_choice': 'adam'}\n",
    "]\n",
    "\n",
    "plot_save_dir = \"./figures/cnn_loss_plots\"\n",
    "os.makedirs(plot_save_dir, exist_ok=True)\n",
    "\n",
    "best_classification_model, best_classification_loss, best_classification_combination = None, float('inf'), None\n",
    "best_regression_model, best_regression_loss, best_regression_combination = None, float('inf'), None\n",
    "\n",
    "for task in ['classification', 'regression']:\n",
    "    for idx, params in enumerate(hyperparam_combinations, 1):\n",
    "        loss_figure_save_path = os.path.join(\n",
    "            plot_save_dir,\n",
    "            f\"{task}_loss_combination_{idx}_lr_{params['lr']}_dropout_{params['dropout_rate']}_layers_{params['num_conv_layers']}_opt_{params['optimizer_choice']}.png\"\n",
    "        )\n",
    "        model = CNN(\n",
    "            task=task,\n",
    "            num_classes=4 if task == 'classification' else 1,\n",
    "            num_conv_layers=params['num_conv_layers'],\n",
    "            dropout_rate=params['dropout_rate'],\n",
    "            optimizer_choice=params['optimizer_choice'],\n",
    "            device='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "            loss_figure_save_path = loss_figure_save_path\n",
    "        )\n",
    "\n",
    "        model.fit(train_loader, val_loader, epochs=2, lr=params['lr'])\n",
    "        \n",
    "        criterion = nn.CrossEntropyLoss() if task == 'classification' else nn.MSELoss()\n",
    "        val_loss = model.evaluate(val_loader, criterion=criterion)\n",
    "        \n",
    "        if task == 'classification':\n",
    "            if val_loss < best_classification_loss:\n",
    "                best_classification_model = model\n",
    "                best_classification_loss = val_loss\n",
    "                best_classification_combination = params\n",
    "        else:  # task == 'regression'\n",
    "            if val_loss < best_regression_loss:\n",
    "                best_regression_model = model\n",
    "                best_regression_loss = val_loss\n",
    "                best_regression_combination = params\n",
    "\n",
    "best_params = {\n",
    "    \"best_classification_combination\": best_classification_combination,\n",
    "    \"best_regression_combination\": best_regression_combination\n",
    "}\n",
    "\n",
    "params_file_path = os.path.join(plot_save_dir, \"best_model_params.json\")\n",
    "with open(params_file_path, 'w') as json_file:\n",
    "    json.dump(best_params, json_file, indent=4)\n",
    "\n",
    "print(\"Best Classification Model Combination:\", best_classification_combination)\n",
    "print(\"Best Regression Model Combination:\", best_regression_combination)\n",
    "print(f\"Best parameters saved to {params_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_best_params(file_path):\n",
    "    with open(file_path, 'r') as json_file:\n",
    "        params = json.load(json_file)\n",
    "    return params\n",
    "\n",
    "loaded_params = read_best_params(params_file_path)\n",
    "print(\"Loaded Parameters:\", loaded_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1000 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def visualize_feature_maps(model, data_loader, feature_map_index=0, num_images=3):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    # Get a batch of images\n",
    "    images, _ = next(iter(data_loader))\n",
    "\n",
    "    # Move images to the appropriate device (CPU or GPU)\n",
    "    images = images.to(model.device)\n",
    "\n",
    "    # Forward pass to get feature maps\n",
    "    with torch.no_grad():\n",
    "        _, feature_maps = model(images, return_feature_maps=True)\n",
    "\n",
    "    # Select the first three images and their feature maps\n",
    "    selected_images = images[:num_images]\n",
    "    selected_maps = [feature_maps[i][:num_images] for i in range(len(feature_maps))]\n",
    "\n",
    "    # Set up the plot\n",
    "    fig, axes = plt.subplots(num_images, len(selected_maps) + 1, figsize=(15, 10))\n",
    "\n",
    "    for i in range(num_images):\n",
    "        # Plot original image\n",
    "        axes[i, 0].imshow(selected_images[i].cpu().numpy().squeeze(), cmap='gray')\n",
    "        axes[i, 0].set_title('Original Image')\n",
    "        axes[i, 0].axis('off')\n",
    "\n",
    "        # Plot feature maps\n",
    "        for j in range(len(selected_maps)):\n",
    "            axes[i, j + 1].imshow(selected_maps[j][i, feature_map_index].cpu().numpy(), cmap='gray')\n",
    "            axes[i, j + 1].axis('off')\n",
    "            if i == 0:\n",
    "                axes[i, j + 1].set_title(f'Layer {j + 1}')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Usage\n",
    "visualize_feature_maps(model, train_loader, feature_map_index=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode_digit(digit):\n",
    "    \"\"\"Creates an 11-dimensional one-hot vector for a single digit or blank.\"\"\"\n",
    "    one_hot = np.zeros(11)\n",
    "    if digit == '*':\n",
    "        one_hot[10] = 1 \n",
    "    else:\n",
    "        one_hot[int(digit)] = 1\n",
    "    return one_hot\n",
    "\n",
    "def one_hot_encode_label(label):\n",
    "    \"\"\"Encodes the label (up to three digits) as a 33-dimensional vector.\"\"\"\n",
    "    label_str = str(label).ljust(3, '*')\n",
    "    one_hot_encoded = np.concatenate([one_hot_encode_digit(digit) for digit in label_str])\n",
    "    return one_hot_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = load_mnist_data(use_label_count=False)\n",
    "\n",
    "train_dataset = MultiMNISTDataset(images['train'], labels['train'], transform=transform)\n",
    "val_dataset = MultiMNISTDataset(images['val'], labels['val'], transform=transform)\n",
    "test_dataset = MultiMNISTDataset(images['test'], labels['test'], transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/30: 100%|██████████| 394/394 [00:09<00:00, 39.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Training Loss: 4.9888\n",
      "Epoch [1/30], Validation Loss: 5.4152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/30: 100%|██████████| 394/394 [00:09<00:00, 40.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/30], Training Loss: 4.1246\n",
      "Epoch [2/30], Validation Loss: 4.9924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/30: 100%|██████████| 394/394 [00:09<00:00, 42.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/30], Training Loss: 3.7269\n",
      "Epoch [3/30], Validation Loss: 4.8242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/30: 100%|██████████| 394/394 [00:09<00:00, 42.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/30], Training Loss: 3.4545\n",
      "Epoch [4/30], Validation Loss: 4.8486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/30: 100%|██████████| 394/394 [00:09<00:00, 40.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/30], Training Loss: 3.2462\n",
      "Epoch [5/30], Validation Loss: 4.8175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/30: 100%|██████████| 394/394 [00:09<00:00, 42.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/30], Training Loss: 3.0984\n",
      "Epoch [6/30], Validation Loss: 5.5019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7/30: 100%|██████████| 394/394 [00:09<00:00, 40.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/30], Training Loss: 2.9926\n",
      "Epoch [7/30], Validation Loss: 4.8026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8/30: 100%|██████████| 394/394 [00:11<00:00, 33.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/30], Training Loss: 2.9086\n",
      "Epoch [8/30], Validation Loss: 4.8351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9/30: 100%|██████████| 394/394 [00:08<00:00, 44.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/30], Training Loss: 2.7775\n",
      "Epoch [9/30], Validation Loss: 4.5205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10/30: 100%|██████████| 394/394 [00:10<00:00, 39.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/30], Training Loss: 2.6349\n",
      "Epoch [10/30], Validation Loss: 4.3639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11/30: 100%|██████████| 394/394 [00:09<00:00, 40.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/30], Training Loss: 2.4956\n",
      "Epoch [11/30], Validation Loss: 4.0491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12/30: 100%|██████████| 394/394 [00:10<00:00, 37.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/30], Training Loss: 2.3204\n",
      "Epoch [12/30], Validation Loss: 4.4107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 13/30: 100%|██████████| 394/394 [00:11<00:00, 35.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/30], Training Loss: 2.1231\n",
      "Epoch [13/30], Validation Loss: 4.3811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 14/30: 100%|██████████| 394/394 [00:10<00:00, 39.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/30], Training Loss: 1.9350\n",
      "Epoch [14/30], Validation Loss: 3.8893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 15/30: 100%|██████████| 394/394 [00:12<00:00, 31.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/30], Training Loss: 1.7835\n",
      "Epoch [15/30], Validation Loss: 3.9149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 16/30: 100%|██████████| 394/394 [00:10<00:00, 36.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/30], Training Loss: 1.6560\n",
      "Epoch [16/30], Validation Loss: 3.8619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 17/30: 100%|██████████| 394/394 [00:11<00:00, 35.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/30], Training Loss: 1.5060\n",
      "Epoch [17/30], Validation Loss: 3.6423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 18/30: 100%|██████████| 394/394 [00:13<00:00, 29.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/30], Training Loss: 1.4228\n",
      "Epoch [18/30], Validation Loss: 3.4240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 19/30: 100%|██████████| 394/394 [00:11<00:00, 33.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/30], Training Loss: 1.2953\n",
      "Epoch [19/30], Validation Loss: 3.5635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 20/30: 100%|██████████| 394/394 [00:11<00:00, 35.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/30], Training Loss: 1.2202\n",
      "Epoch [20/30], Validation Loss: 3.6041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 21/30: 100%|██████████| 394/394 [00:13<00:00, 30.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/30], Training Loss: 1.1289\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MultiLabelCNN(device=device).to(device)\n",
    "model.fit(train_loader, val_loader, epochs=30, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]) tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       dtype=torch.float64)\n",
      "Exact Match Accuracy: 2.43%\n",
      "Hamming Accuracy: 89.70%\n"
     ]
    }
   ],
   "source": [
    "def exact_match_accuracy(preds, labels):\n",
    "    \"\"\"Calculates the exact match accuracy between predictions and labels.\"\"\"\n",
    "    return (preds == labels).all(dim=1).float().mean().item()\n",
    "\n",
    "def hamming_accuracy(preds, labels):\n",
    "    \"\"\"Calculates the Hamming accuracy for multi-label predictions.\"\"\"\n",
    "    return (preds == labels).float().mean().item()\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_loader):\n",
    "    preds = model.predict(test_loader)\n",
    "    labels = torch.cat([labels for _, labels in test_loader])\n",
    "    print(preds[12], labels[12])\n",
    "\n",
    "    exact_acc = exact_match_accuracy(preds, labels)\n",
    "    hamming_acc = hamming_accuracy(preds, labels)\n",
    "    print(f\"Exact Match Accuracy: {exact_acc * 100:.2f}%\")\n",
    "    print(f\"Hamming Accuracy: {hamming_acc * 100:.2f}%\")\n",
    "\n",
    "evaluate_model(model, test_loader)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
