{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necessary Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join('..', '..', 'models', 'cnn')))\n",
    "from cnn import CNN\n",
    "from multilabel_cnn import MultiLabelCNN\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a function load mnist data() that extracts images from the\n",
    "dataset folders and organizes them into separate lists for images and labels\n",
    "corresponding to the train, validation, and test splits. Ensure that the\n",
    "images are loaded from their respective folders without any overlap or\n",
    "mixing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist_data(base_path='../../data/external/double_mnist', use_label_count=False):\n",
    "    images = {\n",
    "        'train': [],\n",
    "        'val': [],\n",
    "        'test': []\n",
    "    }\n",
    "    labels = {\n",
    "        'train': [],\n",
    "        'val': [],\n",
    "        'test': []\n",
    "    }\n",
    "\n",
    "    splits = ['train', 'val', 'test']\n",
    "    for split in splits:\n",
    "        split_path = os.path.join(base_path, split)\n",
    "        for label in os.listdir(split_path):\n",
    "            label_path = os.path.join(split_path, label)\n",
    "            if os.path.isdir(label_path):\n",
    "                for img_name in os.listdir(label_path):\n",
    "                    img_path = os.path.join(label_path, img_name)\n",
    "                    img = Image.open(img_path).convert('L')\n",
    "                    img_array = np.array(img)\n",
    "                    images[split].append(img_array)\n",
    "\n",
    "                    if use_label_count:\n",
    "                        if label == \"0\":\n",
    "                            label_count = 0\n",
    "                        else:\n",
    "                            label_count = len(label)\n",
    "                        labels[split].append(label_count)\n",
    "                    else:\n",
    "                        labels[split].append(one_hot_encode_label(label))\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "images, labels = load_mnist_data(use_label_count=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a class called MultiMNISTDataset that will be used to create\n",
    "dataloaders for training and evaluation purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "class MultiMNISTDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        img = torch.tensor(img, dtype=torch.float32) / 255.0  \n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),         \n",
    "    transforms.Resize((28, 28)),     \n",
    "    transforms.ToTensor(),         \n",
    "])\n",
    "\n",
    "train_dataset = MultiMNISTDataset(images['train'], labels['train'], transform=transform)\n",
    "val_dataset = MultiMNISTDataset(images['val'], labels['val'], transform=transform)\n",
    "test_dataset = MultiMNISTDataset(images['test'], labels['test'], transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the CNN Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./figures/cnn_loss_plots/plot.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:  30%|███       | 119/394 [00:03<00:09, 30.32it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m CNN(task\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregression\u001b[39m\u001b[38;5;124m'\u001b[39m, num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, num_conv_layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,dropout_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, optimizer_choice\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/semester5/smai/assignments/smai-m24-assignments-StarryBadger/models/cnn/cnn.py:79\u001b[0m, in \u001b[0;36mCNN.fit\u001b[0;34m(self, train_loader, val_loader, epochs, lr)\u001b[0m\n\u001b[1;32m     77\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(inputs)\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m     78\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m---> 79\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     81\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/semester5/smai/assignments/smai-m24-assignments-StarryBadger/venv/lib/python3.12/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/semester5/smai/assignments/smai-m24-assignments-StarryBadger/venv/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/semester5/smai/assignments/smai-m24-assignments-StarryBadger/venv/lib/python3.12/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = CNN(task='regression', num_classes=4, num_conv_layers=3,dropout_rate=0.2, optimizer_choice='adam', device=device).to(device)\n",
    "model.fit(train_loader, val_loader, epochs=5, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   True Labels  Predictions Correctness\n",
      "0            3          3.0           ✓\n",
      "1            3          3.0           ✓\n",
      "2            3          3.0           ✓\n",
      "3            3          3.0           ✓\n",
      "4            3          3.0           ✓\n",
      "Results saved to predictions.csv\n",
      "Test Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def calculate_accuracy(model, test_loader, output_file='predictions.csv'):\n",
    "    model.eval()\n",
    "    predictions = model.predict(test_loader)\n",
    "    \n",
    "    true_labels = []\n",
    "    for _, labels in test_loader:\n",
    "        true_labels.append(labels)\n",
    "    true_labels = torch.cat(true_labels).cpu()\n",
    "    predictions = torch.round(predictions).cpu()\n",
    "    \n",
    "    # Create a DataFrame to display true labels, predictions, and correctness\n",
    "    results_df = pd.DataFrame({\n",
    "        'True Labels': true_labels.numpy(),\n",
    "        'Predictions': predictions.numpy(),\n",
    "        'Correctness': ['✓' if true == pred else 'x' for true, pred in zip(true_labels.numpy(), predictions.numpy())]\n",
    "    })\n",
    "    \n",
    "    print(results_df.head())\n",
    "    results_df.to_csv(output_file, index=False)\n",
    "    print(f\"Results saved to {output_file}\")\n",
    "    \n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "    return accuracy\n",
    "\n",
    "accuracy = calculate_accuracy(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./figures/cnn_loss_plots/classification_loss_combination_1_lr_0.001_dropout_0.2_layers_2_activ_relu_opt_adam.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/10:   0%|          | 0/394 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/10: 100%|██████████| 394/394 [00:08<00:00, 43.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Training Loss: 0.2405, Validation Loss: 0.0108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/10: 100%|██████████| 394/394 [00:07<00:00, 50.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Training Loss: 0.0140, Validation Loss: 0.0090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/10: 100%|██████████| 394/394 [00:08<00:00, 46.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Training Loss: 0.0054, Validation Loss: 0.0059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/10: 100%|██████████| 394/394 [00:08<00:00, 48.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Training Loss: 0.0037, Validation Loss: 0.0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/10: 100%|██████████| 394/394 [00:08<00:00, 49.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Training Loss: 0.0019, Validation Loss: 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/10: 100%|██████████| 394/394 [00:08<00:00, 46.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Training Loss: 0.0007, Validation Loss: 0.0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7/10: 100%|██████████| 394/394 [00:08<00:00, 44.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Training Loss: 0.0006, Validation Loss: 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8/10: 100%|██████████| 394/394 [00:09<00:00, 43.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Training Loss: 0.0416, Validation Loss: 0.0089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9/10: 100%|██████████| 394/394 [00:09<00:00, 42.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Training Loss: 0.0032, Validation Loss: 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10/10: 100%|██████████| 394/394 [00:08<00:00, 45.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Training Loss: 0.0016, Validation Loss: 0.0008\n",
      "./figures/cnn_loss_plots/classification_loss_combination_2_lr_0.001_dropout_0.4_layers_2_activ_tanh_opt_adam.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/10: 100%|██████████| 394/394 [00:08<00:00, 44.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Training Loss: 0.2022, Validation Loss: 0.0114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/10: 100%|██████████| 394/394 [00:08<00:00, 46.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Training Loss: 0.0110, Validation Loss: 0.0035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/10: 100%|██████████| 394/394 [00:10<00:00, 38.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Training Loss: 0.0150, Validation Loss: 0.0020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/10: 100%|██████████| 394/394 [00:08<00:00, 46.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Training Loss: 0.0038, Validation Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/10: 100%|██████████| 394/394 [00:08<00:00, 46.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Training Loss: 0.0015, Validation Loss: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/10: 100%|██████████| 394/394 [00:08<00:00, 47.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Training Loss: 0.0085, Validation Loss: 0.0028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7/10: 100%|██████████| 394/394 [00:09<00:00, 43.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Training Loss: 0.0072, Validation Loss: 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8/10: 100%|██████████| 394/394 [00:08<00:00, 45.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Training Loss: 0.0034, Validation Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9/10: 100%|██████████| 394/394 [00:06<00:00, 60.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Training Loss: 0.0016, Validation Loss: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10/10: 100%|██████████| 394/394 [00:08<00:00, 44.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Training Loss: 0.0013, Validation Loss: 0.0007\n",
      "./figures/cnn_loss_plots/classification_loss_combination_3_lr_0.001_dropout_0.2_layers_3_activ_relu_opt_adam.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/10: 100%|██████████| 394/394 [00:10<00:00, 36.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Training Loss: 0.2735, Validation Loss: 0.0162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/10: 100%|██████████| 394/394 [00:09<00:00, 40.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Training Loss: 0.0052, Validation Loss: 0.0020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/10: 100%|██████████| 394/394 [00:11<00:00, 34.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Training Loss: 0.0055, Validation Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/10: 100%|██████████| 394/394 [00:11<00:00, 34.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Training Loss: 0.0005, Validation Loss: 0.0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/10: 100%|██████████| 394/394 [00:11<00:00, 34.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Training Loss: 0.0159, Validation Loss: 0.0042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/10: 100%|██████████| 394/394 [00:11<00:00, 34.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Training Loss: 0.0059, Validation Loss: 0.0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7/10: 100%|██████████| 394/394 [00:12<00:00, 31.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Training Loss: 0.0019, Validation Loss: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8/10: 100%|██████████| 394/394 [00:12<00:00, 31.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Training Loss: 0.0001, Validation Loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9/10: 100%|██████████| 394/394 [00:09<00:00, 39.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Training Loss: 0.0001, Validation Loss: 0.0027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10/10: 100%|██████████| 394/394 [00:13<00:00, 30.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Training Loss: 0.0001, Validation Loss: 0.0000\n",
      "./figures/cnn_loss_plots/classification_loss_combination_4_lr_0.001_dropout_0.4_layers_3_activ_tanh_opt_sgd.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/10: 100%|██████████| 394/394 [00:10<00:00, 38.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Training Loss: 1.1824, Validation Loss: 1.0914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/10: 100%|██████████| 394/394 [00:09<00:00, 39.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Training Loss: 1.1311, Validation Loss: 1.0798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/10: 100%|██████████| 394/394 [00:08<00:00, 44.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Training Loss: 1.1117, Validation Loss: 1.0421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/10: 100%|██████████| 394/394 [00:07<00:00, 52.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Training Loss: 1.0141, Validation Loss: 0.8346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/10: 100%|██████████| 394/394 [00:09<00:00, 42.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Training Loss: 0.7012, Validation Loss: 0.4103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/10: 100%|██████████| 394/394 [00:08<00:00, 45.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Training Loss: 0.2885, Validation Loss: 0.1223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7/10: 100%|██████████| 394/394 [00:11<00:00, 33.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Training Loss: 0.1629, Validation Loss: 0.0863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8/10: 100%|██████████| 394/394 [00:09<00:00, 43.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Training Loss: 0.1204, Validation Loss: 0.0536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9/10: 100%|██████████| 394/394 [00:08<00:00, 48.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Training Loss: 0.0950, Validation Loss: 0.0476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10/10: 100%|██████████| 394/394 [00:10<00:00, 36.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Training Loss: 0.0730, Validation Loss: 0.0242\n",
      "./figures/cnn_loss_plots/classification_loss_combination_5_lr_0.0005_dropout_0.2_layers_2_activ_relu_opt_adam.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/10: 100%|██████████| 394/394 [00:08<00:00, 45.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Training Loss: 0.3230, Validation Loss: 0.0445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/10: 100%|██████████| 394/394 [00:10<00:00, 36.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Training Loss: 0.0353, Validation Loss: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/10: 100%|██████████| 394/394 [00:17<00:00, 22.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Training Loss: 0.0090, Validation Loss: 0.0056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/10: 100%|██████████| 394/394 [00:10<00:00, 36.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Training Loss: 0.0081, Validation Loss: 0.0059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/10: 100%|██████████| 394/394 [00:13<00:00, 29.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Training Loss: 0.0036, Validation Loss: 0.0035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/10: 100%|██████████| 394/394 [00:09<00:00, 42.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Training Loss: 0.0024, Validation Loss: 0.0052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7/10: 100%|██████████| 394/394 [00:08<00:00, 44.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Training Loss: 0.0028, Validation Loss: 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8/10: 100%|██████████| 394/394 [00:08<00:00, 46.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Training Loss: 0.0010, Validation Loss: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9/10: 100%|██████████| 394/394 [00:07<00:00, 51.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Training Loss: 0.0011, Validation Loss: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10/10: 100%|██████████| 394/394 [00:08<00:00, 44.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Training Loss: 0.0064, Validation Loss: 0.0055\n",
      "./figures/cnn_loss_plots/classification_loss_combination_6_lr_0.0005_dropout_0.4_layers_2_activ_tanh_opt_sgd.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/10: 100%|██████████| 394/394 [00:09<00:00, 42.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Training Loss: 1.1790, Validation Loss: 1.0853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/10: 100%|██████████| 394/394 [00:11<00:00, 33.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Training Loss: 1.1198, Validation Loss: 1.0543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/10: 100%|██████████| 394/394 [00:09<00:00, 43.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Training Loss: 1.0657, Validation Loss: 0.9591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/10: 100%|██████████| 394/394 [00:09<00:00, 40.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Training Loss: 0.8748, Validation Loss: 0.6448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/10: 100%|██████████| 394/394 [00:10<00:00, 39.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Training Loss: 0.5767, Validation Loss: 0.3791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/10: 100%|██████████| 394/394 [00:08<00:00, 48.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Training Loss: 0.3992, Validation Loss: 0.2481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7/10: 100%|██████████| 394/394 [00:07<00:00, 51.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Training Loss: 0.3060, Validation Loss: 0.1776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8/10: 100%|██████████| 394/394 [00:08<00:00, 45.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Training Loss: 0.2462, Validation Loss: 0.1648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9/10: 100%|██████████| 394/394 [00:08<00:00, 48.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Training Loss: 0.2110, Validation Loss: 0.1374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10/10: 100%|██████████| 394/394 [00:09<00:00, 40.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Training Loss: 0.1829, Validation Loss: 0.1016\n",
      "./figures/cnn_loss_plots/classification_loss_combination_7_lr_0.0005_dropout_0.2_layers_3_activ_relu_opt_adam.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/10: 100%|██████████| 394/394 [00:11<00:00, 34.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Training Loss: 0.3608, Validation Loss: 0.0184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/10: 100%|██████████| 394/394 [00:10<00:00, 37.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Training Loss: 0.0276, Validation Loss: 0.0032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/10: 100%|██████████| 394/394 [03:36<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Training Loss: 0.0046, Validation Loss: 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/10: 100%|██████████| 394/394 [00:26<00:00, 14.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Training Loss: 0.0021, Validation Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/10: 100%|██████████| 394/394 [00:13<00:00, 28.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Training Loss: 0.0009, Validation Loss: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/10: 100%|██████████| 394/394 [00:13<00:00, 30.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Training Loss: 0.0036, Validation Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7/10: 100%|██████████| 394/394 [00:14<00:00, 27.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Training Loss: 0.0007, Validation Loss: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8/10: 100%|██████████| 394/394 [00:12<00:00, 30.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Training Loss: 0.0256, Validation Loss: 0.0054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9/10: 100%|██████████| 394/394 [00:12<00:00, 32.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Training Loss: 0.0022, Validation Loss: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10/10: 100%|██████████| 394/394 [00:11<00:00, 33.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Training Loss: 0.0005, Validation Loss: 0.0001\n",
      "./figures/cnn_loss_plots/classification_loss_combination_8_lr_0.001_dropout_0.4_layers_3_activ_relu_opt_sgd.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/10: 100%|██████████| 394/394 [00:10<00:00, 36.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Training Loss: 1.1796, Validation Loss: 1.0878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/10: 100%|██████████| 394/394 [00:10<00:00, 37.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Training Loss: 1.1210, Validation Loss: 1.0561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/10: 100%|██████████| 394/394 [00:09<00:00, 39.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Training Loss: 1.0593, Validation Loss: 0.9180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/10: 100%|██████████| 394/394 [00:10<00:00, 36.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Training Loss: 0.8479, Validation Loss: 0.6107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/10: 100%|██████████| 394/394 [00:36<00:00, 10.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Training Loss: 0.4496, Validation Loss: 0.1800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/10: 100%|██████████| 394/394 [00:08<00:00, 44.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Training Loss: 0.1968, Validation Loss: 0.0809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7/10: 100%|██████████| 394/394 [00:08<00:00, 44.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Training Loss: 0.1314, Validation Loss: 0.0502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8/10: 100%|██████████| 394/394 [01:30<00:00,  4.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Training Loss: 0.0981, Validation Loss: 0.0379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9/10: 100%|██████████| 394/394 [03:04<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Training Loss: 0.0712, Validation Loss: 0.0501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10/10: 100%|██████████| 394/394 [00:09<00:00, 40.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Training Loss: 0.0557, Validation Loss: 0.0189\n",
      "./figures/cnn_loss_plots/regression_loss_combination_1_lr_0.001_dropout_0.2_layers_2_activ_relu_opt_adam.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/10: 100%|██████████| 394/394 [00:10<00:00, 36.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Training Loss: 0.1773, Validation Loss: 0.0228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/10: 100%|██████████| 394/394 [00:08<00:00, 45.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Training Loss: 0.0410, Validation Loss: 0.0299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/10: 100%|██████████| 394/394 [00:10<00:00, 36.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Training Loss: 0.0368, Validation Loss: 0.0237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/10: 100%|██████████| 394/394 [01:51<00:00,  3.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Training Loss: 0.0323, Validation Loss: 0.0096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/10: 100%|██████████| 394/394 [02:11<00:00,  2.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Training Loss: 0.0327, Validation Loss: 0.0133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/10: 100%|██████████| 394/394 [02:09<00:00,  3.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Training Loss: 0.0272, Validation Loss: 0.0121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7/10: 100%|██████████| 394/394 [02:04<00:00,  3.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Training Loss: 0.0272, Validation Loss: 0.0201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8/10: 100%|██████████| 394/394 [02:09<00:00,  3.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Training Loss: 0.0246, Validation Loss: 0.0090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9/10: 100%|██████████| 394/394 [02:02<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Training Loss: 0.0242, Validation Loss: 0.0327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10/10: 100%|██████████| 394/394 [02:05<00:00,  3.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Training Loss: 0.0222, Validation Loss: 0.0050\n",
      "./figures/cnn_loss_plots/regression_loss_combination_2_lr_0.001_dropout_0.4_layers_2_activ_tanh_opt_adam.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/10: 100%|██████████| 394/394 [02:00<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Training Loss: 0.1758, Validation Loss: 0.0154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/10: 100%|██████████| 394/394 [02:06<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Training Loss: 0.0693, Validation Loss: 0.0134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/10: 100%|██████████| 394/394 [02:08<00:00,  3.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Training Loss: 0.0601, Validation Loss: 0.0151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/10: 100%|██████████| 394/394 [02:03<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Training Loss: 0.0588, Validation Loss: 0.0082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/10: 100%|██████████| 394/394 [02:03<00:00,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Training Loss: 0.0554, Validation Loss: 0.0094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/10: 100%|██████████| 394/394 [02:09<00:00,  3.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Training Loss: 0.0494, Validation Loss: 0.0089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7/10: 100%|██████████| 394/394 [01:59<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Training Loss: 0.0480, Validation Loss: 0.0071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8/10: 100%|██████████| 394/394 [01:18<00:00,  5.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Training Loss: 0.0441, Validation Loss: 0.0064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9/10: 100%|██████████| 394/394 [00:08<00:00, 45.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Training Loss: 0.0411, Validation Loss: 0.0087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10/10: 100%|██████████| 394/394 [00:05<00:00, 71.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Training Loss: 0.0394, Validation Loss: 0.0098\n",
      "./figures/cnn_loss_plots/regression_loss_combination_3_lr_0.001_dropout_0.2_layers_3_activ_relu_opt_adam.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/10: 100%|██████████| 394/394 [00:08<00:00, 48.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Training Loss: 0.1662, Validation Loss: 0.0231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/10: 100%|██████████| 394/394 [00:07<00:00, 49.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Training Loss: 0.0418, Validation Loss: 0.0123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/10: 100%|██████████| 394/394 [00:07<00:00, 49.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Training Loss: 0.0345, Validation Loss: 0.0088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/10: 100%|██████████| 394/394 [00:09<00:00, 41.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Training Loss: 0.0282, Validation Loss: 0.0110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/10: 100%|██████████| 394/394 [00:09<00:00, 41.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Training Loss: 0.0300, Validation Loss: 0.0057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/10: 100%|██████████| 394/394 [00:08<00:00, 45.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Training Loss: 0.0247, Validation Loss: 0.0081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7/10: 100%|██████████| 394/394 [00:08<00:00, 46.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Training Loss: 0.0244, Validation Loss: 0.0053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8/10: 100%|██████████| 394/394 [00:08<00:00, 44.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Training Loss: 0.0221, Validation Loss: 0.0039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9/10: 100%|██████████| 394/394 [00:11<00:00, 33.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Training Loss: 0.0215, Validation Loss: 0.0220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10/10: 100%|██████████| 394/394 [00:11<00:00, 34.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Training Loss: 0.0203, Validation Loss: 0.0042\n",
      "./figures/cnn_loss_plots/regression_loss_combination_4_lr_0.001_dropout_0.4_layers_3_activ_tanh_opt_sgd.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/10: 100%|██████████| 394/394 [00:10<00:00, 37.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Training Loss: 0.5806, Validation Loss: 0.1793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/10: 100%|██████████| 394/394 [00:10<00:00, 38.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Training Loss: 0.2146, Validation Loss: 0.1263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/10: 100%|██████████| 394/394 [00:10<00:00, 37.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Training Loss: 0.1584, Validation Loss: 0.0930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/10: 100%|██████████| 394/394 [00:10<00:00, 36.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Training Loss: 0.1237, Validation Loss: 0.0746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/10: 100%|██████████| 394/394 [00:09<00:00, 39.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Training Loss: 0.0969, Validation Loss: 0.0468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/10: 100%|██████████| 394/394 [00:09<00:00, 39.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Training Loss: 0.0643, Validation Loss: 0.0262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7/10: 100%|██████████| 394/394 [00:09<00:00, 40.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Training Loss: 0.0451, Validation Loss: 0.0177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8/10: 100%|██████████| 394/394 [00:10<00:00, 38.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Training Loss: 0.0377, Validation Loss: 0.0147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9/10: 100%|██████████| 394/394 [00:10<00:00, 36.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Training Loss: 0.0336, Validation Loss: 0.0155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10/10: 100%|██████████| 394/394 [00:10<00:00, 36.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Training Loss: 0.0312, Validation Loss: 0.0116\n",
      "./figures/cnn_loss_plots/regression_loss_combination_5_lr_0.0005_dropout_0.2_layers_2_activ_relu_opt_adam.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/10: 100%|██████████| 394/394 [00:09<00:00, 41.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Training Loss: 0.1791, Validation Loss: 0.0496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/10: 100%|██████████| 394/394 [00:08<00:00, 44.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Training Loss: 0.0443, Validation Loss: 0.0459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/10: 100%|██████████| 394/394 [00:09<00:00, 40.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Training Loss: 0.0324, Validation Loss: 0.0146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/10: 100%|██████████| 394/394 [00:08<00:00, 45.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Training Loss: 0.0292, Validation Loss: 0.0103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/10: 100%|██████████| 394/394 [00:08<00:00, 43.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Training Loss: 0.0286, Validation Loss: 0.0107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/10: 100%|██████████| 394/394 [00:09<00:00, 43.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Training Loss: 0.0247, Validation Loss: 0.0153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7/10: 100%|██████████| 394/394 [00:08<00:00, 46.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Training Loss: 0.0240, Validation Loss: 0.0083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8/10: 100%|██████████| 394/394 [00:09<00:00, 39.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Training Loss: 0.0252, Validation Loss: 0.0122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9/10: 100%|██████████| 394/394 [00:09<00:00, 40.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Training Loss: 0.0236, Validation Loss: 0.0070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10/10: 100%|██████████| 394/394 [00:07<00:00, 49.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Training Loss: 0.0224, Validation Loss: 0.0065\n",
      "./figures/cnn_loss_plots/regression_loss_combination_6_lr_0.0005_dropout_0.4_layers_2_activ_tanh_opt_sgd.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/10: 100%|██████████| 394/394 [00:07<00:00, 53.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Training Loss: 0.6339, Validation Loss: 0.2644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/10: 100%|██████████| 394/394 [00:07<00:00, 52.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Training Loss: 0.2191, Validation Loss: 0.1211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/10: 100%|██████████| 394/394 [00:06<00:00, 58.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Training Loss: 0.1777, Validation Loss: 0.0986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/10: 100%|██████████| 394/394 [00:09<00:00, 43.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Training Loss: 0.1627, Validation Loss: 0.0964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/10: 100%|██████████| 394/394 [00:05<00:00, 67.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Training Loss: 0.1561, Validation Loss: 0.0893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/10: 100%|██████████| 394/394 [00:05<00:00, 71.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Training Loss: 0.1445, Validation Loss: 0.0859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7/10: 100%|██████████| 394/394 [00:06<00:00, 63.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Training Loss: 0.1357, Validation Loss: 0.0779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8/10: 100%|██████████| 394/394 [00:05<00:00, 66.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Training Loss: 0.1241, Validation Loss: 0.0708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9/10: 100%|██████████| 394/394 [00:06<00:00, 58.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Training Loss: 0.1142, Validation Loss: 0.0673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10/10: 100%|██████████| 394/394 [00:05<00:00, 73.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Training Loss: 0.0987, Validation Loss: 0.0576\n",
      "./figures/cnn_loss_plots/regression_loss_combination_7_lr_0.0005_dropout_0.2_layers_3_activ_relu_opt_adam.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/10: 100%|██████████| 394/394 [00:06<00:00, 57.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Training Loss: 0.2334, Validation Loss: 0.0235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/10: 100%|██████████| 394/394 [00:08<00:00, 47.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Training Loss: 0.0421, Validation Loss: 0.0257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/10: 100%|██████████| 394/394 [00:07<00:00, 52.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Training Loss: 0.0318, Validation Loss: 0.0196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/10: 100%|██████████| 394/394 [00:08<00:00, 44.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Training Loss: 0.0283, Validation Loss: 0.0261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/10: 100%|██████████| 394/394 [00:07<00:00, 51.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Training Loss: 0.0277, Validation Loss: 0.0133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/10: 100%|██████████| 394/394 [00:08<00:00, 47.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Training Loss: 0.0251, Validation Loss: 0.0127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7/10: 100%|██████████| 394/394 [00:09<00:00, 42.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Training Loss: 0.0242, Validation Loss: 0.0099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8/10: 100%|██████████| 394/394 [00:08<00:00, 44.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Training Loss: 0.0236, Validation Loss: 0.0037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9/10: 100%|██████████| 394/394 [00:08<00:00, 45.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Training Loss: 0.0234, Validation Loss: 0.0050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10/10: 100%|██████████| 394/394 [00:09<00:00, 42.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Training Loss: 0.0239, Validation Loss: 0.0106\n",
      "./figures/cnn_loss_plots/regression_loss_combination_8_lr_0.001_dropout_0.4_layers_3_activ_relu_opt_sgd.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/10: 100%|██████████| 394/394 [00:08<00:00, 49.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Training Loss: 0.6105, Validation Loss: 0.2001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/10: 100%|██████████| 394/394 [00:07<00:00, 49.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Training Loss: 0.2175, Validation Loss: 0.1246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/10: 100%|██████████| 394/394 [00:07<00:00, 51.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Training Loss: 0.1628, Validation Loss: 0.0950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/10: 100%|██████████| 394/394 [00:12<00:00, 31.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Training Loss: 0.1363, Validation Loss: 0.0819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/10: 100%|██████████| 394/394 [00:10<00:00, 36.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Training Loss: 0.1166, Validation Loss: 0.0623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/10: 100%|██████████| 394/394 [00:10<00:00, 36.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Training Loss: 0.0891, Validation Loss: 0.0393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7/10: 100%|██████████| 394/394 [00:10<00:00, 35.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Training Loss: 0.0571, Validation Loss: 0.0232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8/10: 100%|██████████| 394/394 [00:11<00:00, 33.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Training Loss: 0.0422, Validation Loss: 0.0174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9/10: 100%|██████████| 394/394 [00:12<00:00, 32.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Training Loss: 0.0342, Validation Loss: 0.0182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10/10: 100%|██████████| 394/394 [00:10<00:00, 36.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Training Loss: 0.0326, Validation Loss: 0.0141\n",
      "Best Classification Model Combination: {'lr': 0.001, 'dropout_rate': 0.2, 'num_conv_layers': 3, 'optimizer_choice': 'adam', 'activation_function': 'relu'}\n",
      "Best Regression Model Combination: {'lr': 0.001, 'dropout_rate': 0.2, 'num_conv_layers': 3, 'optimizer_choice': 'adam', 'activation_function': 'relu'}\n",
      "Best parameters saved to ./figures/cnn_loss_plots/best_model_params.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "hyperparam_combinations = [\n",
    "    {'lr': 0.001, 'dropout_rate': 0.2, 'num_conv_layers': 2, 'optimizer_choice': 'adam', 'activation_function': 'relu'},\n",
    "    {'lr': 0.001, 'dropout_rate': 0.4, 'num_conv_layers': 2, 'optimizer_choice': 'adam', 'activation_function': 'tanh'},\n",
    "    {'lr': 0.001, 'dropout_rate': 0.2, 'num_conv_layers': 3, 'optimizer_choice': 'adam', 'activation_function': 'relu'},\n",
    "    {'lr': 0.001, 'dropout_rate': 0.4, 'num_conv_layers': 3, 'optimizer_choice': 'sgd', 'activation_function': 'tanh'},\n",
    "    {'lr': 0.0005, 'dropout_rate': 0.2, 'num_conv_layers': 2, 'optimizer_choice': 'adam', 'activation_function': 'relu'},\n",
    "    {'lr': 0.0005, 'dropout_rate': 0.4, 'num_conv_layers': 2, 'optimizer_choice': 'sgd', 'activation_function': 'tanh'},\n",
    "    {'lr': 0.0005, 'dropout_rate': 0.2, 'num_conv_layers': 3, 'optimizer_choice': 'adam', 'activation_function': 'relu'},\n",
    "    {'lr': 0.001, 'dropout_rate': 0.4, 'num_conv_layers': 3, 'optimizer_choice': 'sgd', 'activation_function': 'relu'}\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "plot_save_dir = \"./figures/cnn_loss_plots\"\n",
    "os.makedirs(plot_save_dir, exist_ok=True)\n",
    "\n",
    "best_classification_model, best_classification_loss, best_classification_combination = None, float('inf'), None\n",
    "best_regression_model, best_regression_loss, best_regression_combination = None, float('inf'), None\n",
    "\n",
    "for task in ['classification', 'regression']:\n",
    "    for idx, params in enumerate(hyperparam_combinations, 1):\n",
    "        loss_figure_save_path = os.path.join(\n",
    "            plot_save_dir,\n",
    "            f\"{task}_loss_combination_{idx}_lr_{params['lr']}_dropout_{params['dropout_rate']}_layers_{params['num_conv_layers']}_activ_{params['activation_function']}_opt_{params['optimizer_choice']}.png\"\n",
    "        )\n",
    "        model = CNN(\n",
    "            task=task,\n",
    "            num_classes=4 if task == 'classification' else 1,\n",
    "            num_conv_layers=params['num_conv_layers'],\n",
    "            dropout_rate=params['dropout_rate'],\n",
    "            optimizer_choice=params['optimizer_choice'],\n",
    "            activation_function=['activation_function'],\n",
    "            device=device,\n",
    "            loss_figure_save_path = loss_figure_save_path\n",
    "        )\n",
    "\n",
    "        model.fit(train_loader, val_loader, epochs=10, lr=params['lr'])\n",
    "        \n",
    "        criterion = nn.CrossEntropyLoss() if task == 'classification' else nn.MSELoss()\n",
    "        val_loss = model.evaluate(val_loader, criterion=criterion)\n",
    "        \n",
    "        if task == 'classification':\n",
    "            if val_loss < best_classification_loss:\n",
    "                best_classification_model = model\n",
    "                best_classification_loss = val_loss\n",
    "                best_classification_combination = params\n",
    "        else:  # task == 'regression'\n",
    "            if val_loss < best_regression_loss:\n",
    "                best_regression_model = model\n",
    "                best_regression_loss = val_loss\n",
    "                best_regression_combination = params\n",
    "\n",
    "best_params = {\n",
    "    \"best_classification_combination\": best_classification_combination,\n",
    "    \"best_regression_combination\": best_regression_combination\n",
    "}\n",
    "\n",
    "params_file_path = os.path.join(plot_save_dir, \"best_model_params.json\")\n",
    "with open(params_file_path, 'w') as json_file:\n",
    "    json.dump(best_params, json_file, indent=4)\n",
    "\n",
    "print(\"Best Classification Model Combination:\", best_classification_combination)\n",
    "print(\"Best Regression Model Combination:\", best_regression_combination)\n",
    "print(f\"Best parameters saved to {params_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Parameters: {'best_classification_combination': {'lr': 0.001, 'dropout_rate': 0.2, 'num_conv_layers': 3, 'optimizer_choice': 'adam', 'activation_function': 'relu'}, 'best_regression_combination': {'lr': 0.001, 'dropout_rate': 0.2, 'num_conv_layers': 3, 'optimizer_choice': 'adam', 'activation_function': 'relu'}}\n"
     ]
    }
   ],
   "source": [
    "def read_best_params(file_path):\n",
    "    with open(file_path, 'r') as json_file:\n",
    "        params = json.load(json_file)\n",
    "    return params\n",
    "\n",
    "loaded_params = read_best_params(params_file_path)\n",
    "print(\"Loaded Parameters:\", loaded_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1000 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def visualize_feature_maps(model, data_loader, feature_map_index=0, num_images=3):\n",
    "    model.eval() \n",
    "\n",
    "    images, _ = next(iter(data_loader))\n",
    "    images = images.to(model.device)\n",
    "    with torch.no_grad():\n",
    "        _, feature_maps = model(images, return_feature_maps=True)\n",
    "    selected_images = images[:num_images]\n",
    "    selected_maps = [feature_maps[i][:num_images] for i in range(len(feature_maps))]\n",
    "\n",
    "    fig, axes = plt.subplots(num_images, len(selected_maps) + 1, figsize=(15, 10))\n",
    "\n",
    "    for i in range(num_images):\n",
    "        axes[i, 0].imshow(selected_images[i].cpu().numpy().squeeze(), cmap='gray')\n",
    "        axes[i, 0].set_title('Original Image')\n",
    "        axes[i, 0].axis('off')\n",
    "\n",
    "        for j in range(len(selected_maps)):\n",
    "            axes[i, j + 1].imshow(selected_maps[j][i, feature_map_index].cpu().numpy(), cmap='gray')\n",
    "            axes[i, j + 1].axis('off')\n",
    "            if i == 0:\n",
    "                axes[i, j + 1].set_title(f'Layer {j + 1}')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_feature_maps(model, train_loader, feature_map_index=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode_digit(digit):\n",
    "    \"\"\"Creates an 11-dimensional one-hot vector for a single digit or blank.\"\"\"\n",
    "    one_hot = np.zeros(11)\n",
    "    if digit == '*':\n",
    "        one_hot[10] = 1 \n",
    "    else:\n",
    "        one_hot[int(digit)] = 1\n",
    "    return one_hot\n",
    "\n",
    "def one_hot_encode_label(label):\n",
    "    \"\"\"Encodes the label (up to three digits) as a 33-dimensional vector.\"\"\"\n",
    "    label_str = str(label).ljust(3, '*')\n",
    "    one_hot_encoded = np.concatenate([one_hot_encode_digit(digit) for digit in label_str])\n",
    "    return one_hot_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = load_mnist_data(use_label_count=False)\n",
    "\n",
    "train_dataset = MultiMNISTDataset(images['train'], labels['train'], transform=transform)\n",
    "val_dataset = MultiMNISTDataset(images['val'], labels['val'], transform=transform)\n",
    "test_dataset = MultiMNISTDataset(images['test'], labels['test'], transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/30: 100%|██████████| 394/394 [00:10<00:00, 36.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Training Loss: 4.9327\n",
      "Epoch [1/30], Validation Loss: 5.3432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/30: 100%|██████████| 394/394 [00:09<00:00, 41.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/30], Training Loss: 4.2289\n",
      "Epoch [2/30], Validation Loss: 4.7570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/30: 100%|██████████| 394/394 [00:10<00:00, 37.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/30], Training Loss: 3.7475\n",
      "Epoch [3/30], Validation Loss: 4.5684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/30: 100%|██████████| 394/394 [00:11<00:00, 34.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/30], Training Loss: 3.3397\n",
      "Epoch [4/30], Validation Loss: 4.1200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/30: 100%|██████████| 394/394 [00:10<00:00, 37.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/30], Training Loss: 3.0723\n",
      "Epoch [5/30], Validation Loss: 4.2165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/30: 100%|██████████| 394/394 [00:11<00:00, 33.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/30], Training Loss: 2.8737\n",
      "Epoch [6/30], Validation Loss: 3.9674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7/30: 100%|██████████| 394/394 [00:11<00:00, 35.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/30], Training Loss: 2.5440\n",
      "Epoch [7/30], Validation Loss: 3.5737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8/30: 100%|██████████| 394/394 [00:10<00:00, 36.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/30], Training Loss: 2.2712\n",
      "Epoch [8/30], Validation Loss: 3.7857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9/30: 100%|██████████| 394/394 [00:10<00:00, 36.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/30], Training Loss: 2.0743\n",
      "Epoch [9/30], Validation Loss: 3.3612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10/30: 100%|██████████| 394/394 [00:11<00:00, 33.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/30], Training Loss: 1.8976\n",
      "Epoch [10/30], Validation Loss: 3.4899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11/30: 100%|██████████| 394/394 [00:12<00:00, 31.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/30], Training Loss: 1.7605\n",
      "Epoch [11/30], Validation Loss: 3.2437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12/30: 100%|██████████| 394/394 [00:11<00:00, 33.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/30], Training Loss: 1.6080\n",
      "Epoch [12/30], Validation Loss: 2.8491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 13/30: 100%|██████████| 394/394 [00:10<00:00, 37.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/30], Training Loss: 1.4991\n",
      "Epoch [13/30], Validation Loss: 3.0675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 14/30: 100%|██████████| 394/394 [00:11<00:00, 33.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/30], Training Loss: 1.3841\n",
      "Epoch [14/30], Validation Loss: 3.2548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 15/30: 100%|██████████| 394/394 [00:11<00:00, 33.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/30], Training Loss: 1.2925\n",
      "Epoch [15/30], Validation Loss: 3.0751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 16/30: 100%|██████████| 394/394 [00:11<00:00, 34.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/30], Training Loss: 1.2117\n",
      "Epoch [16/30], Validation Loss: 3.1065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 17/30: 100%|██████████| 394/394 [00:13<00:00, 29.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/30], Training Loss: 1.1268\n",
      "Epoch [17/30], Validation Loss: 3.1110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 18/30: 100%|██████████| 394/394 [00:11<00:00, 34.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/30], Training Loss: 1.0686\n",
      "Epoch [18/30], Validation Loss: 2.9585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 19/30: 100%|██████████| 394/394 [00:11<00:00, 32.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/30], Training Loss: 0.9791\n",
      "Epoch [19/30], Validation Loss: 2.8761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 20/30: 100%|██████████| 394/394 [00:12<00:00, 31.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/30], Training Loss: 0.9089\n",
      "Epoch [20/30], Validation Loss: 3.3850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 21/30: 100%|██████████| 394/394 [00:24<00:00, 15.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/30], Training Loss: 0.8828\n",
      "Epoch [21/30], Validation Loss: 3.0190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 22/30: 100%|██████████| 394/394 [00:19<00:00, 20.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/30], Training Loss: 0.8100\n",
      "Epoch [22/30], Validation Loss: 3.5362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 23/30: 100%|██████████| 394/394 [00:17<00:00, 21.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/30], Training Loss: 0.7794\n",
      "Epoch [23/30], Validation Loss: 3.3036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 24/30: 100%|██████████| 394/394 [00:19<00:00, 20.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/30], Training Loss: 0.7429\n",
      "Epoch [24/30], Validation Loss: 3.1594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 25/30: 100%|██████████| 394/394 [00:16<00:00, 24.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/30], Training Loss: 0.6883\n",
      "Epoch [25/30], Validation Loss: 3.3565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 26/30: 100%|██████████| 394/394 [00:17<00:00, 21.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/30], Training Loss: 0.6355\n",
      "Epoch [26/30], Validation Loss: 3.3527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 27/30: 100%|██████████| 394/394 [00:19<00:00, 20.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/30], Training Loss: 0.6196\n",
      "Epoch [27/30], Validation Loss: 3.5873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 28/30: 100%|██████████| 394/394 [00:20<00:00, 19.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/30], Training Loss: 0.5927\n",
      "Epoch [28/30], Validation Loss: 3.5816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 29/30: 100%|██████████| 394/394 [00:19<00:00, 19.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/30], Training Loss: 0.5395\n",
      "Epoch [29/30], Validation Loss: 3.6758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 30/30: 100%|██████████| 394/394 [00:21<00:00, 18.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/30], Training Loss: 0.5333\n",
      "Epoch [30/30], Validation Loss: 3.6408\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MultiLabelCNN(num_conv_layers=3,dropout_rate=0.25).to(device)\n",
    "\n",
    "model.fit(train_loader, val_loader, epochs=30, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]) tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       dtype=torch.float64)\n",
      "Exact Match Accuracy: 32.33%\n",
      "Hamming Accuracy: 95.55%\n"
     ]
    }
   ],
   "source": [
    "def exact_match_accuracy(preds, labels):\n",
    "    \"\"\"Calculates the exact match accuracy between predictions and labels.\"\"\"\n",
    "    return (preds == labels).all(dim=1).float().mean().item()\n",
    "\n",
    "def hamming_accuracy(preds, labels):\n",
    "    \"\"\"Calculates the Hamming accuracy for multi-label predictions.\"\"\"\n",
    "    return (preds == labels).float().mean().item()\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_loader):\n",
    "    preds = model.predict(test_loader)\n",
    "    labels = torch.cat([labels for _, labels in test_loader])\n",
    "    print(preds[12], labels[12])\n",
    "\n",
    "    exact_acc = exact_match_accuracy(preds, labels)\n",
    "    hamming_acc = hamming_accuracy(preds, labels)\n",
    "    print(f\"Exact Match Accuracy: {exact_acc * 100:.2f}%\")\n",
    "    print(f\"Hamming Accuracy: {hamming_acc * 100:.2f}%\")\n",
    "\n",
    "evaluate_model(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/30:   7%|▋         | 29/394 [00:00<00:09, 37.57it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 31\u001b[0m\n\u001b[1;32m     18\u001b[0m loss_figure_save_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m     19\u001b[0m     plot_save_dir,\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel_loss_combination_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_lr_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_dropout_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdropout_rate\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_layers_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_conv_layers\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_activ_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactivation_function\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_opt_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimizer_choice\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     21\u001b[0m )\n\u001b[1;32m     22\u001b[0m model \u001b[38;5;241m=\u001b[39m MultiLabelCNN(\n\u001b[1;32m     23\u001b[0m     num_conv_layers\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_conv_layers\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     24\u001b[0m     dropout_rate\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdropout_rate\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m     loss_figure_save_path \u001b[38;5;241m=\u001b[39m loss_figure_save_path\n\u001b[1;32m     29\u001b[0m )\n\u001b[0;32m---> 31\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss() \u001b[38;5;28;01mif\u001b[39;00m task \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassification\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m nn\u001b[38;5;241m.\u001b[39mMSELoss()\n\u001b[1;32m     34\u001b[0m val_loss \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(val_loader, criterion\u001b[38;5;241m=\u001b[39mcriterion)\n",
      "File \u001b[0;32m~/semester5/smai/assignments/smai-m24-assignments-StarryBadger/models/cnn/multilabel_cnn.py:77\u001b[0m, in \u001b[0;36mMultiLabelCNN.fit\u001b[0;34m(self, train_loader, val_loader, epochs, lr)\u001b[0m\n\u001b[1;32m     73\u001b[0m new_labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([labels[:, i:i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m11\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m33\u001b[39m, \u001b[38;5;241m11\u001b[39m)], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     74\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(new_outputs,new_labels)\n\u001b[0;32m---> 77\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     79\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/semester5/smai/assignments/smai-m24-assignments-StarryBadger/venv/lib/python3.12/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/semester5/smai/assignments/smai-m24-assignments-StarryBadger/venv/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/semester5/smai/assignments/smai-m24-assignments-StarryBadger/venv/lib/python3.12/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hyperparam_combinations = [\n",
    "    {'lr': 0.001, 'dropout_rate': 0.2, 'num_conv_layers': 2, 'optimizer_choice': 'adam', 'activation_function': 'relu'},\n",
    "    {'lr': 0.001, 'dropout_rate': 0.4, 'num_conv_layers': 2, 'optimizer_choice': 'adam', 'activation_function': 'tanh'},\n",
    "    {'lr': 0.001, 'dropout_rate': 0.2, 'num_conv_layers': 3, 'optimizer_choice': 'adam', 'activation_function': 'relu'},\n",
    "    {'lr': 0.001, 'dropout_rate': 0.4, 'num_conv_layers': 3, 'optimizer_choice': 'sgd', 'activation_function': 'tanh'},\n",
    "    {'lr': 0.0005, 'dropout_rate': 0.2, 'num_conv_layers': 2, 'optimizer_choice': 'adam', 'activation_function': 'relu'},\n",
    "    {'lr': 0.0005, 'dropout_rate': 0.4, 'num_conv_layers': 2, 'optimizer_choice': 'sgd', 'activation_function': 'tanh'},\n",
    "    {'lr': 0.0005, 'dropout_rate': 0.2, 'num_conv_layers': 3, 'optimizer_choice': 'adam', 'activation_function': 'relu'},\n",
    "    {'lr': 0.001, 'dropout_rate': 0.4, 'num_conv_layers': 3, 'optimizer_choice': 'sgd', 'activation_function': 'relu'}\n",
    "]\n",
    "\n",
    "plot_save_dir = \"./figures/multilabel_cnn_loss_plots\"\n",
    "os.makedirs(plot_save_dir, exist_ok=True)\n",
    "\n",
    "best_multi_classification_model, best_multi_classification_loss, best_multi_classification_combination = None, float('inf'), None\n",
    "\n",
    "for idx, params in enumerate(hyperparam_combinations, 1):\n",
    "    loss_figure_save_path = os.path.join(\n",
    "        plot_save_dir,\n",
    "        f\"multilabel_loss_combination_{idx}_lr_{params['lr']}_dropout_{params['dropout_rate']}_layers_{params['num_conv_layers']}_activ_{params['activation_function']}_opt_{params['optimizer_choice']}.png\"\n",
    "    )\n",
    "    model = MultiLabelCNN(\n",
    "        num_conv_layers=params['num_conv_layers'],\n",
    "        dropout_rate=params['dropout_rate'],\n",
    "        optimizer_choice=params['optimizer_choice'],\n",
    "        activation_function=params['activation_function'],\n",
    "        device=device,\n",
    "        loss_figure_save_path = loss_figure_save_path\n",
    "    )\n",
    "\n",
    "    model.fit(train_loader, val_loader, epochs=30, lr=params['lr'])\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss() if task == 'classification' else nn.MSELoss()\n",
    "    val_loss = model.evaluate(val_loader, criterion=criterion)\n",
    "    \n",
    "    \n",
    "    if val_loss < best_multi_classification_loss:\n",
    "        best_multi_classification_model = model\n",
    "        best_multi_classification_loss = val_loss\n",
    "        best_multi_classification_combination = params\n",
    "\n",
    "best_params = {\n",
    "    \"best_classification_combination\": best_multi_classification_combination\n",
    "}\n",
    "\n",
    "params_file_path = os.path.join(plot_save_dir, \"best_multilabel_model_params.json\")\n",
    "with open(params_file_path, 'w') as json_file:\n",
    "    json.dump(best_params, json_file, indent=4)\n",
    "\n",
    "print(\"Best Classification Model Combination:\", best_classification_combination)\n",
    "print(\"Best Regression Model Combination:\", best_regression_combination)\n",
    "print(f\"Best parameters saved to {params_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
